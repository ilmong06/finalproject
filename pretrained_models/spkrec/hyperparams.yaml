modules:
  embedding_model: !new:speechbrain.lobes.models.ECAPA_TDNN.ECAPA_TDNN
    input_size: 80
    channels: [1024, 1024, 1024, 1024, 3072]
    kernel_sizes: [5, 3, 3, 3, 1]
    dilations: [1, 2, 3, 4, 1]
    attention_channels: 128
    lin_neurons: 192

pretrainer: !new:speechbrain.utils.parameter_transfer.Pretrainer
  collect_in: null
  loadables:
    embedding_model: !ref <modules[embedding_model]>
  paths:
    embedding_model: embedding_model.ckpt
