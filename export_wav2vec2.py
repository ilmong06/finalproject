import os
os.environ["SPEECHBRAIN_LOCAL_FILE_STRATEGY"] = "copy"

from flask import Flask, request, jsonify
from flask_cors import CORS
from speechbrain.pretrained import SpeakerRecognition
from vosk import Model as VoskModel, KaldiRecognizer
from pydub import AudioSegment
from pathlib import Path
import torchaudio
import torch.nn as nn
import torch
import uuid
import json
import traceback
import subprocess
import numpy as np
import matplotlib.pyplot as plt
import wave
from g2pk import G2p
g2p = G2p()
import os
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "google_stt_key.json"
from google.cloud import speech

# âœ… MatchboxNet ì¸ì½”ë” ì„í¬íŠ¸
from train_matchboxnet_protonet import MatchboxNetEncoder

# âœ… Flask ì„¤ì •
app = Flask(__name__)
CORS(app)

# âœ… Vosk ëª¨ë¸ ë¡œë“œ
vosk_model = VoskModel("model")

def segment_waveform(waveform, sample_rate=16000, segment_ms=250  ):
    segment_samples = int(sample_rate * segment_ms / 1000  )
    segments = []
    for i in range(0, waveform.shape[1], segment_samples):
        chunk = waveform[:, i:i+segment_samples]
        if chunk.shape[1] == segment_samples:
            energy = chunk.pow(2).mean().item()
            if energy > 1e-8:
                segments.append(chunk)
    return segments

# âœ… MatchboxNet ëª¨ë¸ ë¡œë“œ
matchbox_model = MatchboxNetEncoder()
if os.path.exists("matchbox_model.pt"):
    state = torch.load("matchbox_model.pt", map_location="cpu")
    matchbox_model.load_state_dict(state["model"])
    matchbox_model.eval()
    print("âœ… matchbox_model.pt ë¡œë“œ ì™„ë£Œ")
else:
    print("âš ï¸ matchbox_model.pt ì—†ìŒ â†’ í‚¤ì›Œë“œ ë“±ë¡ë§Œ ê°€ëŠ¥")

# âœ… í™”ì ì¸ì‹ ëª¨ë¸
speaker_model = SpeakerRecognition.from_hparams(source="speechbrain/spkrec-ecapa-voxceleb")
TEMP_VECTORS_FILE = "registered_vectors.json"
FINAL_VECTOR_FILE = "registered_speaker.json"

# âœ… í™”ì ë“±ë¡
@app.route("/register", methods=["POST"])
def register_speaker():
    if "file" not in request.files:
        return jsonify({"error": "No file part"}), 400
    file = request.files["file"]
    if file.filename == "":
        return jsonify({"error": "No selected file"}), 400

    temp_filename = f"register_{uuid.uuid4().hex}.wav"
    file.save(temp_filename)

    try:
        audio = AudioSegment.from_file(temp_filename).set_frame_rate(16000).set_channels(1)
        audio.export(temp_filename, format="wav")
        waveform, sr = torchaudio.load(temp_filename)
        embedding = speaker_model.encode_batch(waveform).squeeze().numpy()
        norm_vector = embedding / np.linalg.norm(embedding)

        vectors = []
        if os.path.exists(TEMP_VECTORS_FILE):
            with open(TEMP_VECTORS_FILE, "r") as f:
                vectors = json.load(f)
        vectors.append(norm_vector.tolist())
        with open(TEMP_VECTORS_FILE, "w") as f:
            json.dump(vectors, f)

        if len(vectors) == 4:
            vectors_np = np.array(vectors)
            mean_vector = np.mean(vectors_np, axis=0)
            final_vector = mean_vector / np.linalg.norm(mean_vector)
            with open(FINAL_VECTOR_FILE, "w") as f:
                json.dump(final_vector.tolist(), f)
            os.remove(TEMP_VECTORS_FILE)
            return jsonify({"message": "í™”ì ë“±ë¡ ì™„ë£Œ (4/4)"})
        else:
            return jsonify({"message": f"ë“±ë¡ {len(vectors)}/4 ì™„ë£Œ"})

    except Exception as e:
        return jsonify({"error": str(e)}), 500
    finally:
        os.remove(temp_filename)

@app.route("/register_keyword", methods=["POST"])
def register_keyword():
    raw_keyword = request.form.get("keyword")
    keyword = g2p(raw_keyword).replace(" ", "")
    if not keyword or "file" not in request.files:
        return jsonify({"error": "í‚¤ì›Œë“œ ë˜ëŠ” íŒŒì¼ ì—†ìŒ"}), 400

    save_dir = Path("data/custom") / keyword
    save_dir.mkdir(parents=True, exist_ok=True)

    existing = list(save_dir.glob("*.wav"))
    index = len(existing) + 1
    save_path = save_dir / f"record_{index}.wav"

    try:
        file = request.files["file"]
        file.save(str(save_path))
        audio = AudioSegment.from_file(str(save_path))
        audio = audio.set_frame_rate(16000).set_channels(1)
        audio.export(str(save_path), format="wav")

        print(f"[DEBUG] â–¶ï¸ record_{index}.wav ì €ì¥ ì™„ë£Œ")

        if index == 6:
            vectors = []
            for i in range(1, 7):
                wav_path = save_dir / f"record_{i}.wav"
                waveform, sr = torchaudio.load(wav_path)
                segments = segment_waveform(waveform)

                print(f"[DEBUG] ğŸ” record_{i}.wav ì„¸ê·¸ë¨¼íŠ¸ ìˆ˜: {len(segments)}")

                if len(segments) == 0:
                    print(f"[WARN] âŒ ì„¸ê·¸ë¨¼íŠ¸ ì—†ìŒ â†’ {wav_path}ëŠ” ë¬´ì‹œë¨")
                    continue

                for seg in segments:
                    with torch.no_grad():
                        seg = seg.unsqueeze(0)  # [1, 1, T]
                        emb = matchbox_model(seg).squeeze().mean(dim=-1).numpy()
                    emb = emb / np.linalg.norm(emb)  # âœ… ì •ê·œí™”
                    vectors.append(np.array(emb).flatten().tolist())  # âœ… list[float] í˜•íƒœë¡œ ì €ì¥

            print(f"[DEBUG] âœ… ìƒì„±ëœ ë²¡í„° ìˆ˜: {len(vectors)}")

            if len(vectors) == 0:
                return jsonify({"error": "âŒ í‚¤ì›Œë“œ ë²¡í„° ìƒì„± ì‹¤íŒ¨: ì„¸ê·¸ë¨¼íŠ¸ ì—†ìŒ"}), 500

            # âœ… label_map.jsonì— ì €ì¥
            label_map_path = "label_map.json"
            if os.path.exists(label_map_path):
                with open(label_map_path, "r") as f:
                    label_map = json.load(f)
            else:
                label_map = {}

            # ğŸ” ìµœì¢… ì €ì¥
            label_map[keyword] = [v if isinstance(v, list) else v.tolist() for v in vectors]

            with open(label_map_path, "w") as f:
                json.dump(label_map, f, indent=2)

            print(f"[DEBUG] ğŸ’¾ label_map.json ì €ì¥ ì™„ë£Œ: í‚¤ì›Œë“œ={keyword}, ë²¡í„°={len(vectors)}")

            subprocess.run(["python", "train_fewshot.py"])
            return jsonify({"message": f"{keyword} í‚¤ì›Œë“œ ë“±ë¡ ì™„ë£Œ âœ…"}), 200
        else:
            return jsonify({"message": f"{keyword} í‚¤ì›Œë“œ {index}/6 ë…¹ìŒ ì €ì¥ ì™„ë£Œ"}), 200

    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500


# âœ… STT + í™”ì + í‚¤ì›Œë“œ ì¸ì¦
@app.route("/stt", methods=["POST"])
def transcribe():
    if "file" not in request.files:
        return jsonify({"error": "No file part"}), 400

    file = request.files["file"]
    if file.filename == "":
        return jsonify({"error": "No selected file"}), 400

    temp_filename = f"temp_{uuid.uuid4().hex}.wav"
    file.save(temp_filename)

    try:
        audio = AudioSegment.from_file(temp_filename).set_frame_rate(16000).set_channels(1)
        audio.export(temp_filename, format="wav")
        waveform, sr = torchaudio.load(temp_filename)

        # ğŸ” í™”ì ì¸ì¦
        speaker_embedding = speaker_model.encode_batch(waveform)
        speaker_vector = speaker_embedding.squeeze().numpy()
        norm_vector = speaker_vector / np.linalg.norm(speaker_vector)

        if not os.path.exists(FINAL_VECTOR_FILE):
            return jsonify({"error": "ë“±ë¡ëœ í™”ìê°€ ì—†ìŠµë‹ˆë‹¤"}), 403
        with open(FINAL_VECTOR_FILE, "r") as f:
            registered_vector = np.array(json.load(f)).flatten()

        sim_sp = float(np.dot(norm_vector, registered_vector))
        print(f"[DEBUG] ğŸ” í™”ì ìœ ì‚¬ë„: {sim_sp:.4f}")

        # âœ… Google STTë¡œ ë¨¼ì € ìŒì„± ì¸ì‹
        try:
            client = speech.SpeechClient()
            with open(temp_filename, "rb") as audio_file:
                content = audio_file.read()
            audio_g = speech.RecognitionAudio(content=content)
            config = speech.RecognitionConfig(
                encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
                sample_rate_hertz=16000,
                language_code="ko-KR",
            )
            response = client.recognize(config=config, audio=audio_g)
            transcript = " ".join(result.alternatives[0].transcript for result in response.results)
            print(f"[DEBUG] ğŸ—£ï¸ Google STT ê²°ê³¼: {transcript}")
        except Exception as stt_err:
            transcript = ""
            print(f"[ERROR] Google STT ì‹¤íŒ¨: {stt_err}")

        # âœ… KoG2Pë¡œ í…ìŠ¤íŠ¸ë¥¼ ë°œìŒ ë‹¨ìœ„ë¡œ ë³€í™˜
        phonetic_transcript = g2p(transcript).replace(" ", "")
        print(f"[DEBUG] ğŸ”¤ ë³€í™˜ëœ ë°œìŒ: {phonetic_transcript}")

        # âœ… label_map.json ê¸°ë°˜ í‚¤ì›Œë“œ ìœ ì‚¬ë„ ê³„ì‚°
        if not os.path.exists("label_map.json"):
            return jsonify({"error": "ë“±ë¡ëœ í‚¤ì›Œë“œ ì—†ìŒ"}), 403

        with open("label_map.json", "r") as f:
            label_map = json.load(f)

        best_keyword = None
        best_score = -1
        segment, sr = torchaudio.load(temp_filename)
        segments = segment_waveform(segment)

        segment_embeddings = []
        for seg in segments:
            with torch.no_grad():
                seg = seg.unsqueeze(0)
                emb = matchbox_model(seg).squeeze().mean(dim=-1).numpy()
            emb = emb / np.linalg.norm(emb)
            segment_embeddings.append(emb)

        for keyword, vec_list in label_map.items():
            phonetic_keyword = g2p(keyword).replace(" ", "")
            if phonetic_keyword in phonetic_transcript:
                # ê°€ì¥ ë†’ì€ ìœ ì‚¬ë„ë¥¼ best_scoreë¡œ
                for emb in segment_embeddings:
                    for ref_vec in vec_list:
                        ref_vec = np.array(ref_vec)
                        if emb.shape != ref_vec.shape:
                            continue
                        score = float(np.dot(emb, ref_vec))
                        if score > best_score:
                            best_score = score
                            best_keyword = keyword

        sim_kw = best_score
        print(f"[DEBUG] ğŸ” í‚¤ì›Œë“œ ìœ ì‚¬ë„: {sim_kw:.4f}")

        if sim_kw < 0.7:
            return jsonify({
                "error": "í‚¤ì›Œë“œ ì¸ì¦ ì‹¤íŒ¨",
                "triggered_keyword": best_keyword,
                "similarity": round(sim_kw, 4),
                "text": transcript
            }), 403

        return jsonify({
            "text": transcript.strip(),
            "speaker_similarity": round(sim_sp, 4),
            "triggered_keyword": best_keyword,
            "keyword_similarity": round(sim_kw, 4),
            "s_total": round(sim_sp + sim_kw, 4)
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": str(e)}), 500
    finally:
        if os.path.exists(temp_filename):
            try:
                os.remove(temp_filename)
            except Exception as e:
                print("[WARN] íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨:", e)

# âœ… ì‹¤í–‰
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5000)
